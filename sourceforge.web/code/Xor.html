<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">

<!--
Syntax highlighting generated by Web C Plus Plus software v0.8.4
Webcpp Copyright (C)2001-2004 Jeffrey Bakker under the GNU GPL
Get webcpp at http://webcpp.sf.net
-->

<html>
<head>
<title>../src/demo/java/org/jlinalg/demo/Xor.java</title>
<link rel="stylesheet" type="text/css" href="jlinalg.css"/>
</head>
<body>

<div class="webcpp">
<pre>

<font CLASS=comment>/*
 * This file is part of JLinAlg (&lt;http://jlinalg.sourceforge.net/&gt;).
 * 
 * JLinAlg is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Lesser General Public License as
 * published by the Free Software Foundation, either version 3 of
 * the License, or (at your option) any later version.
 * 
 * JLinAlg is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * GNU General Public License for more details.
 * 
 * You should have received a copy of the GNU Lesser General Public
 * License along with JLinALg. If not, see &lt;http://www.gnu.org/licenses/&gt;.
 */</font>
<font CLASS=keyword>package</font> org.jlinalg.demo;

<font CLASS=keyword>import</font> org.jlinalg.LinAlgFactory;
<font CLASS=keyword>import</font> org.jlinalg.Matrix;
<font CLASS=keyword>import</font> org.jlinalg.Vector;
<font CLASS=keyword>import</font> org.jlinalg.doublewrapper.DoubleWrapper;
<font CLASS=keyword>import</font> org.jlinalg.operator.MonadicOperator;

<font CLASS=comment>/**
 * Example showing Exclusive-Or neural net problem using JLinAlg. Example can be
 * easily modified by changing values of inpat, tgpat.
 * 
 * @author Simon D. Levy
 */</font>
<font CLASS=keyword>public</font> <font CLASS=keyword>class</font> Xor
{

	<font CLASS=comment>/**
	 * inpat holds the input part of the training patterns
	 */</font>
	@SuppressWarnings(<font CLASS=dblquot>"boxing"</font>)
	<font CLASS=keyword>private</font> <font CLASS=keytype>static</font> Double[][] inpat <font CLASS=symbols>=</font> {
			{
					<font CLASS=integer>0</font>., <font CLASS=integer>0</font>.
			}, {
					<font CLASS=integer>0</font>., <font CLASS=integer>1</font>.
			}, {
					<font CLASS=integer>1</font>., <font CLASS=integer>0</font>.
			}, {
					<font CLASS=integer>1</font>., <font CLASS=integer>1</font>.
			}
	};

	<font CLASS=comment>/**
	 * tgpat holds the target part of the training patterns
	 */</font>
	@SuppressWarnings(<font CLASS=dblquot>"boxing"</font>)
	<font CLASS=keyword>private</font> <font CLASS=keytype>static</font> Double[][] tgpat <font CLASS=symbols>=</font> {
			{
				<font CLASS=integer>0</font>.
			}, {
				<font CLASS=integer>1</font>.
			}, {
				<font CLASS=integer>1</font>.
			}, {
				<font CLASS=integer>0</font>.
			}
	};

	<font CLASS=comment>/**
	 * how many epochs the training should last
	 */</font>
	<font CLASS=keyword>private</font> <font CLASS=keytype>static</font> <font CLASS=keyword>final</font> <font CLASS=keytype>int</font> NEPOCH <font CLASS=symbols>=</font> <font CLASS=integer>10000</font>;

	<font CLASS=comment>/**
	 * learning rate
	 */</font>
	<font CLASS=keyword>private</font> <font CLASS=keytype>static</font> <font CLASS=keyword>final</font> <font CLASS=keytype>double</font> ETA <font CLASS=symbols>=</font> <font CLASS=floatpt>0.1</font>;

	<font CLASS=comment>/**
	 * the momentum
	 */</font>
	<font CLASS=keyword>private</font> <font CLASS=keytype>static</font> <font CLASS=keyword>final</font> <font CLASS=keytype>double</font> MU <font CLASS=symbols>=</font> <font CLASS=floatpt>0.9</font>;

	<font CLASS=comment>/**
	 * the number of hidden units
	 */</font>
	<font CLASS=keyword>private</font> <font CLASS=keytype>static</font> <font CLASS=keyword>final</font> <font CLASS=keytype>int</font> NHID <font CLASS=symbols>=</font> <font CLASS=integer>3</font>;

	<font CLASS=comment>/**
	 * used to create vectors and arrays of {@link DoubleWrapper}s
	 */</font>
	<font CLASS=keyword>private</font> LinAlgFactory&lt;DoubleWrapper&gt; df;

	<font CLASS=comment>/**
	 * the number of inputs
	 */</font>
	<font CLASS=keytype>int</font> ninp;

	<font CLASS=comment>/**
	 * the number of outputs
	 */</font>
	<font CLASS=keytype>int</font> nout;

	<font CLASS=comment>/**
	 * the number of patterns
	 */</font>
	<font CLASS=keytype>int</font> npat;

	<font CLASS=comment>/**
	 * the weights between the input and hidden layer
	 */</font>
	<font CLASS=keyword>private</font> Matrix&lt;DoubleWrapper&gt; wih; <font CLASS=comment>// input-&gt;hidden weights</font>

	<font CLASS=comment>/**
	 * the weights between the hidden and output layer
	 */</font>
	<font CLASS=keyword>private</font> Matrix&lt;DoubleWrapper&gt; who; <font CLASS=comment>// hidden-&gt;output weights</font>

	<font CLASS=comment>/**
	 * the biases used in the hidden layer
	 */</font>
	<font CLASS=keyword>private</font> Vector&lt;DoubleWrapper&gt; bh; <font CLASS=comment>// bias on hidden</font>

	<font CLASS=comment>/**
	 * the biases used in the output layer
	 */</font>
	<font CLASS=keyword>private</font> Vector&lt;DoubleWrapper&gt; bo; <font CLASS=comment>// bias on output</font>

	<font CLASS=comment>/**
	 * Create an instance of this class and ininitialise some arrays.
	 */</font>
	<font CLASS=keyword>public</font> Xor()
	{
		df <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> LinAlgFactory&lt;DoubleWrapper&gt;(DoubleWrapper.FACTORY);

		<font CLASS=comment>// this allows us to generalize to new problems</font>
		ninp <font CLASS=symbols>=</font> inpat[<font CLASS=integer>0</font>].length;
		nout <font CLASS=symbols>=</font> tgpat[<font CLASS=integer>0</font>].length;
		npat <font CLASS=symbols>=</font> inpat.length;

		<font CLASS=comment>// weights are initially random</font>
		wih <font CLASS=symbols>=</font> df.gaussianNoise(ninp, NHID);
		who <font CLASS=symbols>=</font> df.gaussianNoise(NHID, nout);

		<font CLASS=comment>// biases are initially random</font>
		bh <font CLASS=symbols>=</font> df.gaussianNoise(NHID);
		bo <font CLASS=symbols>=</font> df.gaussianNoise(nout);
	}

	<font CLASS=comment>/**
	 * train the network the {@link #NEPOCH} times on all training patterns.
	 */</font>
	<font CLASS=keyword>public</font> <font CLASS=keytype>void</font> train()
	{

		<font CLASS=comment>// space savers</font>
		SigmoidOperator sgop <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> SigmoidOperator();
		SigdervOperator sdop <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> SigdervOperator();
		DoubleWrapper eta <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> DoubleWrapper(ETA);
		DoubleWrapper mu <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> DoubleWrapper(MU);
		DoubleWrapper npatd <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> DoubleWrapper(npat);
		DoubleWrapper errd <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> DoubleWrapper(npat * nout);

		<font CLASS=comment>// initialize momentum terms for weight, bias changes</font>
		Matrix&lt;DoubleWrapper&gt; dwih1 <font CLASS=symbols>=</font> df.zeros(ninp, NHID);
		Matrix&lt;DoubleWrapper&gt; dwho1 <font CLASS=symbols>=</font> df.zeros(NHID, nout);
		Vector&lt;DoubleWrapper&gt; dbh1 <font CLASS=symbols>=</font> df.zeros(NHID);
		Vector&lt;DoubleWrapper&gt; dbo1 <font CLASS=symbols>=</font> df.zeros(nout);

		<font CLASS=comment>// train for specified number of epochs</font>
		<font CLASS=keyword>for</font> (<font CLASS=keytype>int</font> i <font CLASS=symbols>=</font> <font CLASS=integer>0</font>; i &lt; NEPOCH; <font CLASS=symbols>++</font>i) {

			<font CLASS=comment>// initialize weight, bias changes</font>
			Matrix&lt;DoubleWrapper&gt; dwih <font CLASS=symbols>=</font> df.zeros(ninp, NHID);
			Matrix&lt;DoubleWrapper&gt; dwho <font CLASS=symbols>=</font> df.zeros(NHID, nout);
			Vector&lt;DoubleWrapper&gt; dbh <font CLASS=symbols>=</font> df.zeros(NHID);
			Vector&lt;DoubleWrapper&gt; dbo <font CLASS=symbols>=</font> df.zeros(nout);

			<font CLASS=comment>// initialize squared error</font>
			Vector&lt;DoubleWrapper&gt; sqrerr <font CLASS=symbols>=</font> df.zeros(nout);

			<font CLASS=comment>// loop over patterns</font>
			<font CLASS=keyword>for</font> (<font CLASS=keytype>int</font> j <font CLASS=symbols>=</font> <font CLASS=integer>0</font>; j &lt; npat; <font CLASS=symbols>++</font>j) {

				Vector&lt;DoubleWrapper&gt; ai <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> Vector&lt;DoubleWrapper&gt;(inpat[j],
						DoubleWrapper.FACTORY);

				// run forward pass
				Vector&lt;DoubleWrapper&gt; ah <font CLASS=symbols>=</font> ai.multiply(wih).add(bh).apply(sgop);
				Vector&lt;DoubleWrapper&gt; ao <font CLASS=symbols>=</font> ah.multiply(who).add(bo).apply(sgop);

				// compute output error/delta from target
				Vector&lt;DoubleWrapper&gt; eo <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> Vector&lt;DoubleWrapper&gt;(tgpat[j],
						DoubleWrapper.FACTORY).subtract(ao);
				Vector&lt;DoubleWrapper&gt; dlo <font CLASS=symbols>=</font> eo.arrayMultiply(ao.apply(sdop));

				// compute hidden error/delta by back-prop from output delta
				Vector&lt;DoubleWrapper&gt; eh <font CLASS=symbols>=</font> dlo.multiply(who.transpose());
				Vector&lt;DoubleWrapper&gt; dlh <font CLASS=symbols>=</font> eh.arrayMultiply(ah.apply(sdop));

				// accumulate weight<font CLASS=symbols>-</font> and bias<font CLASS=symbols>-</font> changes using the Delta Rule
				dwih <font CLASS=symbols>=</font> dwih.add(ai.transposeAndMultiply(dlh));
				dwho <font CLASS=symbols>=</font> dwho.add(ah.transposeAndMultiply(dlo));
				dbh <font CLASS=symbols>=</font> dbh.add(dlh);
				dbo <font CLASS=symbols>=</font> dbo.add(dlo);

				// accumulate squared error
				sqrerr <font CLASS=symbols>=</font> sqrerr.add(eo.arrayMultiply(eo));
			}

			<font CLASS=comment>// update weight and biases</font>
			wih <font CLASS=symbols>=</font> wih.add(dwih.divide(npatd).multiply(eta)).add(
					dwih1.divide(npatd).multiply(mu));
			who <font CLASS=symbols>=</font> who.add(dwho.divide(npatd).multiply(eta)).add(
					dwho1.divide(npatd).multiply(mu));
			bh <font CLASS=symbols>=</font> bh.add(dbh.divide(npatd).multiply(eta)).add(
					dbh1.divide(npatd).multiply(mu));
			bo <font CLASS=symbols>=</font> bo.add(dbo.divide(npatd).multiply(eta)).add(
					dbo1.divide(npatd).multiply(mu));

			<font CLASS=comment>// recall weight, bias changes for momentum on next epoch</font>
			dwih1 <font CLASS=symbols>=</font> dwih;
			dwho1 <font CLASS=symbols>=</font> dwho;
			dbh1 <font CLASS=symbols>=</font> dbh;
			dbo1 <font CLASS=symbols>=</font> dbo;

			<font CLASS=comment>// report RMS error first, last, every 1000 epochs</font>
			<font CLASS=keyword>if</font> (i <font CLASS=symbols>==</font> <font CLASS=integer>0</font> <font CLASS=symbols>||</font> i == NEPOCH - <font CLASS=integer>1</font> || ((i + <font CLASS=integer>1</font>) % <font CLASS=integer>1000</font>) <font CLASS=symbols>==</font> <font CLASS=integer>0</font>) {
				System.err
						.println(<font CLASS=dblquot>"EPOCH: "</font>
								<font CLASS=symbols>+</font> (i <font CLASS=symbols>+</font> <font CLASS=integer>1</font>)
								<font CLASS=symbols>+</font> <font CLASS=dblquot>"\tRMS ERROR: "</font>
								<font CLASS=symbols>+</font> Math.sqrt(((sqrerr.sum()).divide(errd))
										.doubleValue()));
			}
		}
	}

	<font CLASS=comment>/**
	 * test the performance of the neural net on the training patterns.
	 */</font>
	<font CLASS=keyword>public</font> <font CLASS=keytype>void</font> test()
	{
		SigmoidOperator sgop <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> SigmoidOperator();

		<font CLASS=keyword>for</font> (<font CLASS=keytype>int</font> j <font CLASS=symbols>=</font> <font CLASS=integer>0</font>; j &lt; npat; <font CLASS=symbols>++</font>j) {

			Vector&lt;DoubleWrapper&gt; ai <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> Vector&lt;DoubleWrapper&gt;(inpat[j],
					DoubleWrapper.FACTORY);
			Vector&lt;DoubleWrapper&gt; tg <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> Vector&lt;DoubleWrapper&gt;(tgpat[j],
					DoubleWrapper.FACTORY);

			<font CLASS=comment>// run forward pass</font>
			Vector&lt;DoubleWrapper&gt; ah <font CLASS=symbols>=</font> ai.multiply(wih).add(bh).apply(sgop);
			Vector&lt;DoubleWrapper&gt; ao <font CLASS=symbols>=</font> ah.multiply(who).add(bo).apply(sgop);

			<font CLASS=comment>// report actual, target output</font>
			System.out.println(ao.toString().substring(<font CLASS=integer>2</font>, <font CLASS=integer>10</font>) <font CLASS=symbols>+</font> <font CLASS=dblquot>"  "</font> <font CLASS=symbols>+</font> tg);
		}
	}

	<font CLASS=comment>/**
	 * operator defining the sigmoid squashing function
	 */</font>
	<font CLASS=keyword>private</font> <font CLASS=keyword>class</font> SigmoidOperator
			<font CLASS=keyword>implements</font> MonadicOperator&lt;DoubleWrapper&gt;
	{
		@Override
		<font CLASS=keyword>public</font> DoubleWrapper apply(DoubleWrapper x)
		{
			<font CLASS=keytype>double</font> dx <font CLASS=symbols>=</font> x.getValue();
			<font CLASS=keyword>return</font> <font CLASS=keyword>new</font> DoubleWrapper(<font CLASS=integer>1</font> / (<font CLASS=integer>1</font> <font CLASS=symbols>+</font> Math.exp(-dx)));
		}
	}

	<font CLASS=comment>/**
	 * operator defining the first derivative of the sigmoid w.r.t. activation
	 */</font>
	<font CLASS=keyword>private</font> <font CLASS=keyword>class</font> SigdervOperator
			<font CLASS=keyword>implements</font> MonadicOperator&lt;DoubleWrapper&gt;
	{
		@Override
		<font CLASS=keyword>public</font> DoubleWrapper apply(DoubleWrapper x)
		{
			<font CLASS=keytype>double</font> dx <font CLASS=symbols>=</font> (x).getValue();
			<font CLASS=keyword>return</font> <font CLASS=keyword>new</font> DoubleWrapper(dx * (<font CLASS=integer>1</font> <font CLASS=symbols>-</font> dx));
		}
	}

	<font CLASS=comment>/**
	 * Start the demo.
	 * 
	 * @param argv
	 *            ignored
	 */</font>
	<font CLASS=keyword>public</font> <font CLASS=keytype>static</font> <font CLASS=keytype>void</font> main(String[] argv)
	{

		Xor xor <font CLASS=symbols>=</font> <font CLASS=keyword>new</font> Xor();
		xor.train();
		xor.test();
	}
}



</pre>

</div>


</body>
</html>
